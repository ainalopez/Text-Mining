{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Oriented Programming - Quick and dirty Introduction\n",
    "\n",
    "In this session, we go through a toy example of object oriented programming in python and then look at the skeleton class of a document. Clearly, this topic is vast and requires a much more through treatment than being given here. But I find it more useful to introduce you to concepts because we need them rather than because they exist. \n",
    "\n",
    "#### Why will we use object oriented programming in this class?\n",
    "Amongst the many many reasons that OOP makes sense, for us the most important one is:\n",
    "\n",
    "1. __Reusability__\n",
    "We want to be able to write all our code for every document once and then call it again and again. Having stand alone functinons not only increases the amount of _house keeping_ but will also require you to change code at different places everytime your requirements change.\n",
    "\n",
    "2. __Encapsulation__\n",
    "Remember that you will have hundreds of documents and will have to define properties for each one of them. For example, how long is every document or what are its tokens. OOP allows you to define all of these properties at one place and then the details of these implementations can be hidden.\n",
    "\n",
    "#### Important Terminology\n",
    "\n",
    "1. __Class__: Is _dna_ or _blueprint_ for an object that has to be modeled. Contains attributes that contins its properties and methods that characterize its behaviors.\n",
    "\n",
    "2. __Instance__: An individual object of a class.\n",
    "\n",
    "3. __Instantiation__: The creation of an instance of a class.\n",
    "\n",
    "4. __Object__: A unique instance of a class. An object comprises both data members (class variables and instance variables) and methods.\n",
    "\n",
    "5. __Class variable__: A variable that is shared by all instances of a class. They are defined within a class but outside any of the class's methods\n",
    "\n",
    "6. __Instance variable__: A variable that is defined inside a method and belongs only to the current instance of a class.\n",
    "\n",
    "7. __Data member__: A class variable or instance variable that holds data associated with a class and its objects.\n",
    "\n",
    "8. __Method__ : A function that is defined in a class definition. \n",
    "\n",
    "So all the chit chat aside lets get down to it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk import PorterStemmer\n",
    "import re\n",
    "\n",
    "\"\"\"\n",
    "This is a class sherlock. \n",
    "Notice how it is defined with the keyword `class` and a name that begins with a capital letter\n",
    "\"\"\"\n",
    "class Document():\n",
    "    \n",
    "    \"\"\" The Doc class rpresents a class of individul documents\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, speech_year, speech_pres, speech_text):\n",
    "        \"\"\"\n",
    "        The __init__ method is called everytime an object is instantiated.\n",
    "        This is where you will define all the properties of the object that it must have\n",
    "        when it is `born`.\n",
    "        \"\"\"\n",
    "        \n",
    "        #These are data members\n",
    "        self.year = speech_year\n",
    "        self.pres = speech_pres\n",
    "        self.text = speech_text.lower()\n",
    "        self.tokens = np.array(wordpunct_tokenize(self.text))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def token_clean(self,length):\n",
    "\n",
    "        \"\"\" \n",
    "        description: strip out non-alpha tokens and tokens of length > 'length'\n",
    "        input: length: cut off length \n",
    "        \"\"\"\n",
    "\n",
    "        self.tokens = np.array([t for t in self.tokens if (t.isalpha() and len(t) > length)])\n",
    "\n",
    "\n",
    "    def stopword_remove(self, stopwords):\n",
    "\n",
    "        \"\"\"\n",
    "        description: Remove stopwords from tokens.\n",
    "        input: stopwords: a suitable list of stopwords\n",
    "        \"\"\"\n",
    " \n",
    "        self.tokens = np.array([t for t in self.tokens if t not in stopwords])\n",
    "\n",
    "\n",
    "    def stem(self):\n",
    "\n",
    "        \"\"\"\n",
    "        description: Stem tokens with Porter Stemmer.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.tokens = np.array([PorterStemmer().stem(t) for t in self.tokens])\n",
    "        \n",
    "    def demo_self():\n",
    "        print 'this will error out'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self\n",
    "Notice the `self` keyword that is present all over the place in the class. `self` tells python which object it needs to work with. \n",
    "\n",
    "1. Therefore every method should have a `self` parameter specified.\n",
    "2. Notice that when the method is called the reference to the object is passed implicitly.\n",
    "3. Every data member of the class needs to be referred to using `self`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Document instance at 0x109836ea8>\n",
      "['this' 'is' 'a' 'chicken']\n",
      "demo_self() takes no arguments (1 given)\n"
     ]
    }
   ],
   "source": [
    "#Instantiating an object.  \n",
    "speech1 = Document('1986', 'Rooster', 'this is a chicken')\n",
    "print speech1\n",
    "\n",
    "#Accessing data members\n",
    "print speech1.tokens\n",
    "\n",
    "try:\n",
    "    speech1.demo_self()\n",
    "except Exception as ex:\n",
    "    print ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of usefulness of classes\n",
    "\n",
    "Use this [link](http://www.codeskulptor.org/#user41_X9owzYCGupNiKYr.py) to see how useful classes can be. The link leads to a code I wrote two years ago that implements a very naive version of the game Asteroids. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A skeleton class structure for documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "import nltk\n",
    "import re\n",
    "import math \n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from itertools import repeat\n",
    "\n",
    "\n",
    "class Corpus():\n",
    "    \n",
    "    \"\"\" \n",
    "    The Corpus class represents a document collection\n",
    "     \n",
    "    \"\"\"\n",
    "    def __init__(self, doc_data, stopword_file, clean_length):\n",
    "        \"\"\"\n",
    "        Notice that the __init__ method is invoked everytime an object of the class\n",
    "        is instantiated\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        #Initialise documents by invoking the appropriate class\n",
    "        self.docs = [Document(doc[0], doc[1], doc[2]) for doc in doc_data] \n",
    "        \n",
    "        self.N = len(self.docs)\n",
    "        self.clean_length = clean_length\n",
    "        \n",
    "        #get a list of stopwords\n",
    "        self.create_stopwords(stopword_file, clean_length)\n",
    "        \n",
    "        #stopword removal, token cleaning and stemming to docs\n",
    "        self.clean_docs(2)\n",
    "        \n",
    "        #create vocabulary\n",
    "        self.corpus_tokens()\n",
    "        \n",
    "    def clean_docs(self, length):\n",
    "        \"\"\" \n",
    "        Applies stopword removal, token cleaning and stemming to docs\n",
    "        \"\"\"\n",
    "        for doc in self.docs:\n",
    "            doc.token_clean(length)\n",
    "            doc.stopword_remove(self.stopwords)\n",
    "            doc.stem()        \n",
    "    \n",
    "    def create_stopwords(self, stopword_file, length):\n",
    "        \"\"\"\n",
    "        description: parses a file of stowords, removes words of length 'length' and \n",
    "        stems it\n",
    "        input: length: cutoff length for words\n",
    "               stopword_file: stopwords file to parse\n",
    "        \"\"\"\n",
    "        \n",
    "        with codecs.open(stopword_file,'r','utf-8') as f: raw = f.read()\n",
    "        \n",
    "        self.stopwords = (np.array([PorterStemmer().stem(word) \n",
    "                                    for word in list(raw.splitlines()) if len(word) > length]))\n",
    "        \n",
    "     \n",
    "    def corpus_tokens(self):\n",
    "        \"\"\"\n",
    "        description: create a set of all all tokens or in other words a vocabulary\n",
    "        \"\"\"\n",
    "        \n",
    "        #initialise an empty set\n",
    "        self.token_set = set()\n",
    "        for doc in self.docs:\n",
    "            self.token_set = self.token_set.union(doc.tokens) \n",
    "            \n",
    "    def document_term_matrix(self):\n",
    "        \"\"\"\n",
    "        description:  returns a D by V array of frequency counts\n",
    "        \"\"\"  \n",
    "        # subroutine: computes the counts of each vocabulary in the document\n",
    "        def counts(doc):\n",
    "            # initialize a matrix\n",
    "            term_mat = [0]*len(self.token_set)\n",
    "            for token in doc.tokens:\n",
    "                term_mat[list(self.token_set).index(token)] = term_mat[list(self.token_set).index(token)] + 1\n",
    "            return term_mat;\n",
    "            \n",
    "        self.doc_term_matrix = []\n",
    "        \n",
    "        for doc in self.docs:\n",
    "            self.doc_term_matrix.append([doc.pres + \" \" + doc.year, counts(doc)])\n",
    "\n",
    "\n",
    "      \n",
    "    def tf_idf(self):\n",
    "        \"\"\"\n",
    "        description:  returns a D by V array of tf-idf scores\n",
    "        \"\"\"\n",
    "        # Compute inverse document frequency \n",
    "        idf = [0]*len(self.token_set)\n",
    "        for token in self.token_set:\n",
    "            ind = 0\n",
    "            for doc in self.docs:\n",
    "                if token in doc.tokens:\n",
    "                    ind += 1 \n",
    "            idf[list(self.token_set).index(token)] = math.log(self.N/ind)\n",
    "        \n",
    "        # Create a subroutine that computes tf_idf for one document\n",
    "        def tfidf(doc):\n",
    "            term_mat = [0]*len(self.token_set)\n",
    "            for token in doc.tokens:\n",
    "                term_mat[list(self.token_set).index(token)] = term_mat[list(self.token_set).index(token)] + 1 \n",
    "        \n",
    "            for i,term in enumerate(term_mat):\n",
    "                if term != 0:\n",
    "                    term_mat[i] = (1 + math.log(term)) * idf[i]\n",
    "            return term_mat;\n",
    "        \n",
    "        #tf_idf\n",
    "        self.tf_idf_matrix = []\n",
    "        for doc in self.docs:\n",
    "            self.tf_idf_matrix.append([doc.pres + \" \" + doc.year, tfidf(doc)])\n",
    "            \n",
    "            \n",
    "        \n",
    "    def dict_rank(self, n, dictionary, token_repr):\n",
    "        \"\"\"\n",
    "        description:  returns the top n documents based on a given dictionary and represenation of tokens\n",
    "        \"\"\"\n",
    "        if token_repr == \"tf-idf\":\n",
    "            self.tf_idf()\n",
    "            representation = self.tf_idf_matrix\n",
    "            \n",
    "        if token_repr == \"doc-term\":\n",
    "            self.document_term_matrix()\n",
    "            representation = self.doc_term_matrix\n",
    "            \n",
    "        # Return top n docs based on dictionary given\n",
    "        score = []\n",
    "        x=self.token_set\n",
    "        x=list(x)\n",
    "        for token in x: \n",
    "            try:\n",
    "                score.append(dictionary[token])\n",
    "            except: \n",
    "                score.append(0)\n",
    "\n",
    "        # get a vector with all the scores in order\n",
    "        score=[int(x) for x in score]\n",
    "        rank = {}\n",
    "        elements=range(len(representation))\n",
    "   \n",
    "        for i in elements:\n",
    "            rank[representation[i][0]] = np.dot(score,representation[i][1])\n",
    "            \n",
    "        # Get sorted view of the keys.\n",
    "        s = sorted(rank, key=rank.get, reverse=True)[0:(n-1)]\n",
    "        \n",
    "        ranking = {}\n",
    "        for key in s:\n",
    "            ranking[key] =  rank[key]\n",
    "        \n",
    "        return ranking \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Document():\n",
    "    \n",
    "    \"\"\" The Doc class rpresents a class of individul documents\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, speech_year, speech_pres, speech_text):\n",
    "        self.year = speech_year\n",
    "        self.pres = speech_pres\n",
    "        self.text = speech_text.lower()\n",
    "        self.tokens = np.array(wordpunct_tokenize(self.text))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def token_clean(self,length):\n",
    "\n",
    "        \"\"\" \n",
    "        description: strip out non-alpha tokens and tokens of length > 'length'\n",
    "        input: length: cut off length \n",
    "        \"\"\"\n",
    "\n",
    "        self.tokens = np.array([t for t in self.tokens if (t.isalpha() and len(t) > length)])\n",
    "\n",
    "\n",
    "    def stopword_remove(self, stopwords):\n",
    "\n",
    "        \"\"\"\n",
    "        description: Remove stopwords from tokens.\n",
    "        input: stopwords: a suitable list of stopwords\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        self.tokens = np.array([t for t in self.tokens if t not in stopwords])\n",
    "\n",
    "\n",
    "    def stem(self):\n",
    "\n",
    "        \"\"\"\n",
    "        description: Stem tokens with Porter Stemmer.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.tokens = np.array([PorterStemmer().stem(t) for t in self.tokens])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the presedential speech dataset to demonstrate how the class works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_text(textraw, regex):\n",
    "    \"\"\"takes raw string and performs two operations\n",
    "    1. Breaks text into a list of speech, president and speech\n",
    "    2. breaks speech into paragraphs\n",
    "    \"\"\"\n",
    "    prs_yr_spch_reg = re.compile(regex, re.MULTILINE|re.DOTALL)\n",
    "    \n",
    "    #Each tuple contains the year, last ane of the president and the speech text\n",
    "    prs_yr_spch = prs_yr_spch_reg.findall(textraw)\n",
    "    \n",
    "    #convert immutabe tuple to mutable list\n",
    "    prs_yr_spch = [list(tup) for tup in prs_yr_spch]\n",
    "    \n",
    "    for i in range(len(prs_yr_spch)):\n",
    "        prs_yr_spch[i][2] = prs_yr_spch[i][2].replace('\\n', '')\n",
    "    \n",
    "    #sort\n",
    "    prs_yr_spch.sort()\n",
    "    \n",
    "    return(prs_yr_spch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exercise 2: \n",
    "\n",
    "text = open(\"/Users/ainalopez/Downloads/text_mining-master/data/pres_speech/sou_all copy.txt\", 'r').read()\n",
    "#text = open(\"/home/yaroslav/Projects/text_mining/data/pres_speech/sou_all.txt\", 'r').read()\n",
    "regex = \"_(\\d{4}).*?_[a-zA-Z]+.*?_[a-zA-Z]+.*?_([a-zA-Z]+)_\\*+(\\\\n{2}.*?)\\\\n{3}\"\n",
    "pres_speech_list = parse_text(text, regex)\n",
    "\n",
    "#Instantite the corpus class\n",
    "# corpus = Corpus(pres_speech_list, '/home/yaroslav/Projects/text_mining/data/stopwords/stopwords.txt', 2)\n",
    "corpus = Corpus(pres_speech_list, '/Users/ainalopez/Downloads/text_mining-master-2/data/stopwords/stopwords.txt', 2)\n",
    "\n",
    "# Import dictionary from excel file\n",
    "import pandas as pd\n",
    "#df = pd.read_excel(\"/home/yaroslav/Dropbox/BGSE/3rd Term/Text Mining/LoughranMcDonald_MasterDictionary_2014.xlsx\", skiprows=0)\n",
    "df = pd.read_excel(\"/Users/ainalopez/Downloads/dictionary1.xlsx\", skiprows=0)\n",
    "w = df['Word']\n",
    "words = [str(x).lower() for x in df['Word']]\n",
    "words=[PorterStemmer().stem(t) for t in words]\n",
    "score = [str(x).lower() for x in df['Positive']] # or any other method\n",
    "dictionary=dict(zip(words,score))\n",
    "\n",
    "# Applying dict_rank function\n",
    "X1 = corpus.dict_rank(corpus.N, dictionary,\"doc-term\")\n",
    "X2 = corpus.dict_rank(corpus.N, dictionary,\"tf-idf\")\n",
    "\n",
    "# Print the Ranking \n",
    "print sorted(X1, key=X1.get, reverse=True)\n",
    "print sorted(X2, key=X2.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130559.963176,\n",
      "108333.40409,\n",
      "99350.8241101,\n",
      "86602.0861312,\n",
      "86568.5988541,\n",
      "76838.4816609,\n",
      "72258.1006625,\n",
      "68536.8041623,\n",
      "67600.6735489,\n",
      "67060.9908068,\n",
      "65986.7441174,\n",
      "63267.8868743,\n",
      "62706.1738366,\n",
      "61872.5503152,\n",
      "61069.4394329,\n",
      "59891.2560132,\n",
      "57982.2560063,\n",
      "57462.4556797,\n",
      "57043.4672759,\n",
      "56723.5703056,\n",
      "55825.1000214,\n",
      "54808.5135905,\n",
      "54403.3280192,\n",
      "52811.8009693,\n",
      "52260.7513738,\n",
      "51802.5737956,\n",
      "51552.5546315,\n",
      "50626.0456879,\n",
      "50190.1493574,\n",
      "50059.3983806,\n",
      "50038.7316494,\n",
      "49200.220772,\n",
      "48433.1102126,\n",
      "48345.1171769,\n",
      "48107.4919067,\n",
      "47752.6207105,\n",
      "46375.7957706,\n",
      "46330.8337656,\n",
      "46150.668827,\n",
      "45737.3984,\n",
      "45396.8732552,\n",
      "44152.9397802,\n",
      "43968.2424233,\n",
      "43130.1418999,\n",
      "43005.8169787,\n",
      "42924.0107171,\n",
      "42583.6845346,\n",
      "41819.6722728,\n",
      "41618.3358291,\n",
      "41371.0819463,\n",
      "40845.9146668,\n",
      "40570.3829871,\n",
      "39963.0980793,\n",
      "39703.4325762,\n",
      "39683.4071173,\n",
      "39640.4245397,\n",
      "39056.8617806,\n",
      "38862.1572823,\n",
      "38641.9109001,\n",
      "38552.1862343,\n",
      "38356.9875164,\n",
      "38317.2002131,\n",
      "37719.3045623,\n",
      "37484.4760753,\n",
      "37436.8799059,\n",
      "37146.14019,\n",
      "37089.2942283,\n",
      "36898.3417458,\n",
      "36363.8228179,\n",
      "36349.2926065,\n",
      "36298.7114817,\n",
      "35903.2472902,\n",
      "35564.3772266,\n",
      "35154.6614137,\n",
      "35092.72301,\n",
      "34973.5307455,\n",
      "34739.6427275,\n",
      "34600.4329653,\n",
      "33482.0557079,\n",
      "33166.7953167,\n",
      "33159.0382874,\n",
      "32874.2469201,\n",
      "32760.7694479,\n",
      "32692.8544962,\n",
      "32092.1805233,\n",
      "31877.5006553,\n",
      "31792.2138509,\n",
      "31565.1355803,\n",
      "31543.2081877,\n",
      "31351.4830433,\n",
      "31237.1923071,\n",
      "30982.3646412,\n",
      "30940.2100842,\n",
      "30635.4084723,\n",
      "30182.0327908,\n",
      "29774.1611598,\n",
      "29439.0742184,\n",
      "29146.4656107,\n",
      "29096.7478462,\n",
      "28735.8323011,\n",
      "28603.4965658,\n",
      "28377.9356037,\n",
      "28085.5818029,\n",
      "28047.6882282,\n",
      "27952.1609391,\n",
      "27664.3441477,\n",
      "27647.2045659,\n",
      "27641.4262503,\n",
      "27617.9412857,\n",
      "26835.7981883,\n",
      "26827.401446,\n",
      "26751.5811271,\n",
      "26599.1064732,\n",
      "26414.9204991,\n",
      "26159.9857989,\n",
      "26145.6555401,\n",
      "25999.1799992,\n",
      "25998.9375783,\n",
      "25840.1419862,\n",
      "25779.6967151,\n",
      "25667.1685984,\n",
      "25649.4655241,\n",
      "25603.8280446,\n",
      "24739.1447248,\n",
      "24558.2704005,\n",
      "24502.874721,\n",
      "24211.2953589,\n",
      "24130.9316631,\n",
      "23579.6742713,\n",
      "23554.3462582,\n",
      "23227.238231,\n",
      "22681.4418379,\n",
      "22576.9591452,\n",
      "22386.0336024,\n",
      "22076.5166422,\n",
      "22036.4908828,\n",
      "21533.3679831,\n",
      "21382.7172803,\n",
      "21380.9494936,\n",
      "21221.9114806,\n",
      "20985.285362,\n",
      "20566.3700914,\n",
      "20415.7193887,\n",
      "20294.6969274,\n",
      "19797.071183,\n",
      "19649.772912,\n",
      "19197.3223702,\n",
      "19107.015032,\n",
      "18877.4785575,\n",
      "18817.0332864,\n",
      "18500.356833,\n",
      "18374.8540913,\n",
      "17931.9554227,\n",
      "17580.2370517,\n",
      "17044.3134234,\n",
      "16821.0171723,\n",
      "16424.6226317,\n",
      "16251.451199,\n",
      "16103.732846,\n",
      "15815.761308,\n",
      "15705.1363646,\n",
      "15277.8337838,\n",
      "15085.1534258,\n",
      "14996.2393484,\n",
      "14917.5288746,\n",
      "14837.2013354,\n",
      "14449.924514,\n",
      "14199.9685278,\n",
      "13885.3010981,\n",
      "13657.0622897,\n",
      "13355.0365201,\n",
      "13070.7216959,\n",
      "13030.6959365,\n",
      "12920.0709931,\n",
      "12502.9235093,\n",
      "12342.1177096,\n",
      "12224.5038445,\n",
      "12092.1617233,\n",
      "11837.2270231,\n",
      "11527.5383074,\n",
      "11250.8864294,\n",
      "11140.261486,\n",
      "10798.934321,\n",
      "10699.6290376,\n",
      "10562.3082024,\n",
      "9984.35491885,\n",
      "9933.7387254,\n",
      "9885.0496354,\n",
      "9457.74705462,\n",
      "9330.58131638,\n",
      "9320.42621943,\n",
      "9307.09635185,\n",
      "9307.09635185,\n",
      "9169.77551666,\n",
      "9169.77551666,\n",
      "9052.16165165,\n",
      "8591.8222331,\n",
      "8355.19611447,\n",
      "8355.19611447,\n",
      "7777.24283091,\n",
      "6672.68168313,\n",
      "6545.51594489,\n",
      "6535.36084794,\n",
      "6384.71014517,\n",
      "6108.05826716,\n",
      "5707.45157817,\n",
      "5707.45157817,\n",
      "5570.13074298,\n",
      "5570.13074298,\n",
      "5570.13074298,\n",
      "5280.14899738,\n",
      "4992.17745942,\n",
      "4715.52558141,\n",
      "3599.64477368,\n",
      "3322.99289567,\n",
      "2785.06537149,\n",
      "2785.06537149,\n",
      "2785.06537149,\n",
      "2785.06537149,\n",
      "2785.06537149,\n",
      "2357.76279071,\n",
      "1392.53268574,\n",
      "1392.53268574,\n",
      "1392.53268574,\n",
      "1392.53268574,\n",
      "1392.53268574,\n",
      "0.0,\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(X2, key=X2.get, reverse = True):\n",
    "    print str(X2[key]) + \",\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106959,\n",
      "1054725,\n",
      "787528,\n",
      "683060,\n",
      "548457,\n",
      "540421,\n",
      "498232,\n",
      "484169,\n",
      "470106,\n",
      "441980,\n",
      "435953,\n",
      "411845,\n",
      "407827,\n",
      "391755,\n",
      "389746,\n",
      "347557,\n",
      "331485,\n",
      "319431,\n",
      "313404,\n",
      "307377,\n",
      "303359,\n",
      "301350,\n",
      "293314,\n",
      "289296,\n",
      "285278,\n",
      "275233,\n",
      "271215,\n",
      "267197,\n",
      "267197,\n",
      "263179,\n",
      "255143,\n",
      "253134,\n",
      "249116,\n",
      "249116,\n",
      "247107,\n",
      "245098,\n",
      "245098,\n",
      "239071,\n",
      "237062,\n",
      "235053,\n",
      "231035,\n",
      "222999,\n",
      "220990,\n",
      "220990,\n",
      "218981,\n",
      "218981,\n",
      "216972,\n",
      "216972,\n",
      "214963,\n",
      "214963,\n",
      "212954,\n",
      "210945,\n",
      "208936,\n",
      "206927,\n",
      "206927,\n",
      "204918,\n",
      "204918,\n",
      "204918,\n",
      "202909,\n",
      "202909,\n",
      "202909,\n",
      "202909,\n",
      "198891,\n",
      "196882,\n",
      "196882,\n",
      "192864,\n",
      "190855,\n",
      "188846,\n",
      "184828,\n",
      "182819,\n",
      "180810,\n",
      "178801,\n",
      "178801,\n",
      "178801,\n",
      "176792,\n",
      "174783,\n",
      "174783,\n",
      "172774,\n",
      "170765,\n",
      "168756,\n",
      "168756,\n",
      "168756,\n",
      "168756,\n",
      "166747,\n",
      "166747,\n",
      "166747,\n",
      "164738,\n",
      "164738,\n",
      "162729,\n",
      "162729,\n",
      "162729,\n",
      "160720,\n",
      "158711,\n",
      "158711,\n",
      "158711,\n",
      "158711,\n",
      "154693,\n",
      "152684,\n",
      "152684,\n",
      "152684,\n",
      "150675,\n",
      "146657,\n",
      "146657,\n",
      "146657,\n",
      "144648,\n",
      "144648,\n",
      "142639,\n",
      "140630,\n",
      "140630,\n",
      "140630,\n",
      "140630,\n",
      "138621,\n",
      "138621,\n",
      "138621,\n",
      "136612,\n",
      "134603,\n",
      "134603,\n",
      "134603,\n",
      "134603,\n",
      "130585,\n",
      "130585,\n",
      "130585,\n",
      "128576,\n",
      "126567,\n",
      "124558,\n",
      "124558,\n",
      "124558,\n",
      "122549,\n",
      "122549,\n",
      "122549,\n",
      "122549,\n",
      "122549,\n",
      "122549,\n",
      "120540,\n",
      "120540,\n",
      "120540,\n",
      "118531,\n",
      "116522,\n",
      "116522,\n",
      "114513,\n",
      "112504,\n",
      "112504,\n",
      "112504,\n",
      "112504,\n",
      "110495,\n",
      "110495,\n",
      "106477,\n",
      "104468,\n",
      "102459,\n",
      "100450,\n",
      "98441,\n",
      "98441,\n",
      "98441,\n",
      "98441,\n",
      "94423,\n",
      "94423,\n",
      "94423,\n",
      "94423,\n",
      "94423,\n",
      "92414,\n",
      "92414,\n",
      "90405,\n",
      "90405,\n",
      "88396,\n",
      "88396,\n",
      "86387,\n",
      "86387,\n",
      "86387,\n",
      "84378,\n",
      "84378,\n",
      "84378,\n",
      "78351,\n",
      "78351,\n",
      "78351,\n",
      "78351,\n",
      "76342,\n",
      "76342,\n",
      "76342,\n",
      "72324,\n",
      "72324,\n",
      "72324,\n",
      "72324,\n",
      "72324,\n",
      "72324,\n",
      "70315,\n",
      "70315,\n",
      "68306,\n",
      "68306,\n",
      "64288,\n",
      "62279,\n",
      "62279,\n",
      "62279,\n",
      "60270,\n",
      "60270,\n",
      "60270,\n",
      "60270,\n",
      "58261,\n",
      "58261,\n",
      "58261,\n",
      "56252,\n",
      "54243,\n",
      "52234,\n",
      "52234,\n",
      "52234,\n",
      "52234,\n",
      "52234,\n",
      "48216,\n",
      "48216,\n",
      "44198,\n",
      "42189,\n",
      "42189,\n",
      "40180,\n",
      "38171,\n",
      "36162,\n",
      "36162,\n",
      "34153,\n",
      "34153,\n",
      "34153,\n",
      "34153,\n",
      "34153,\n",
      "32144,\n",
      "30135,\n",
      "30135,\n",
      "28126,\n",
      "28126,\n",
      "26117,\n",
      "24108,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key in sorted(X1, key=X1.get, reverse = True):\n",
    "    print str(X1[key]) + \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sortedKeY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-77ffc097337a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msortedKey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedKeY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sortedKeY' is not defined"
     ]
    }
   ],
   "source": [
    "for sortedKey in sorted(X1):\n",
    "    print X1[sortedKeY]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Carter 1980', 'Carter 1981', 'Carter 1979', 'Nixon 1974', 'Truman 1946', 'Nixon 1972', 'Taft 1912', 'Taft 1910', 'Roosevelt 1907', 'Roosevelt 1901', 'Roosevelt 1906', 'Carter 1978', 'Roosevelt 1905', 'Taft 1911', 'McKinley 1899', 'Cleveland 1885', 'Polk 1848', 'McKinley 1900', 'Jackson 1830', 'Roosevelt 1908', 'Roosevelt 1904', 'Coolidge 1925', 'Eisenhower 1961', 'Eisenhower 1955', 'McKinley 1898', 'Cleveland 1896', 'Cleveland 1886', 'Buren 1837', 'Truman 1950', 'Tyler 1844', 'Hayes 1880', 'Taft 1909', 'Harrison 1891', 'Jackson 1834', 'Roosevelt 1903', 'Clinton 2000', 'Polk 1847', 'Buren 1839', 'Truman 1953', 'Polk 1846', 'Polk 1845', 'Hayes 1879', 'Hayes 1877', 'Cleveland 1888', 'Arthur 1881', 'Buchanan 1858', 'Roosevelt 1902', 'Harrison 1892', 'Buren 1838', 'Harrison 1889', 'Jackson 1829', 'Coolidge 1926', 'Jackson 1835', 'Cleveland 1895', 'Fillmore 1852', 'Truman 1948', 'Eisenhower 1953', 'Adams 1825', 'Eisenhower 1958', 'Fillmore 1851', 'Hoover 1929', 'Buchanan 1859', 'Cleveland 1894', 'Buchanan 1860', 'Grant 1875', 'Grant 1872', 'Buren 1840', 'Johnson 1867', 'Buchanan 1857', 'Coolidge 1928', 'Kennedy 1962', 'Tyler 1842', 'Eisenhower 1954', 'Jackson 1836', 'Monroe 1824', 'Harrison 1890', 'Cleveland 1893', 'Clinton 1998', 'Eisenhower 1959', 'Johnson 1868', 'Kennedy 1963', 'Pierce 1856', 'Clinton 1999', 'McKinley 1897', 'Hoover 1931', 'Jackson 1833', 'Tyler 1843', 'Coolidge 1924', 'Obama 2014', 'Bush 2005', 'Jackson 1832', 'Coolidge 1927', 'Truman 1949', 'Eisenhower 1960', 'Grant 1874', 'Jackson 1831', 'Johnson 1967', 'Monroe 1823', 'Pierce 1853', 'Bush 2008', 'Hayes 1878', 'Fillmore 1850', 'Clinton 1995', 'Adams 1826', 'Eisenhower 1957', 'Clinton 1997', 'Ford 1977', 'Pierce 1855', 'Pierce 1854', 'Johnson 1865', 'Taylor 1849', 'Truman 1947', 'Reagan 1984', 'Truman 1952', 'Obama 2010', 'Nixon 1971', 'Lincoln 1862', 'Obama 2013', 'Grant 1873', 'Obama 2009', 'Harding 1921', 'Bush 2006', 'Coolidge 1923', 'Kennedy 1961', 'Bush 1989', 'Reagan 1983', 'Reagan 1985', 'Johnson 1866', 'Obama 2011', 'Ford 1976', 'Ford 1975', 'Clinton 1994', 'Clinton 1996', 'Grant 1871', 'Johnson 1968', 'Adams 1827', 'Tyler 1841', 'Adams 1828', 'Monroe 1817', 'Nixon 1970', 'Arthur 1884', 'Arthur 1882', 'Johnson 1966', 'Truman 1951', 'Roosevelt 1943', 'Clinton 1993', 'Arthur 1883', 'Madison 1815', 'Grant 1870', 'Grant 1876', 'Bush 1991', 'Lincoln 1861', 'Wilson 1915', 'Grant 1869', 'Reagan 1988', 'Obama 2012', 'Wilson 1918', 'Bush 2004', 'Johnson 1969', 'Lincoln 1864', 'Bush 2007', 'Reagan 1986', 'Bush 2003', 'Reagan 1982', 'Johnson 1965', 'Monroe 1822', 'Nixon 1973', 'Bush 2001', 'Hoover 1932', 'Monroe 1819', 'Harding 1922', 'Lincoln 1863', 'Roosevelt 1939', 'Monroe 1821', 'Madison 1816', 'Bush 1992', 'Madison 1813', 'Monroe 1818', 'Washington 1796', 'Roosevelt 1941', 'Monroe 1820', 'Wilson 1914', 'Bush 2002', 'Johnson 1964', 'Roosevelt 1936', 'Wilson 1919', 'Reagan 1987', 'Hoover 1930', 'Roosevelt 1944', 'Washington 1795', 'Roosevelt 1934', 'Roosevelt 1935', 'Cleveland 1887', 'Bush 1990', 'Washington 1791', 'Roosevelt 1937', 'Washington 1794', 'Jefferson 1801', 'Roosevelt 1940', 'Reagan 1981', 'Roosevelt 1938', 'Roosevelt 1942', 'Roosevelt 1945', 'Madison 1810', 'Wilson 1913', 'Wilson 1917', 'Madison 1812', 'Jefferson 1804', 'Jefferson 1805', 'Jefferson 1808', 'Jefferson 1806', 'Washington 1792', 'Adams 1800', 'Jefferson 1803', 'Jefferson 1807', 'Adams 1798', 'Wilson 1920', 'Madison 1811', 'Wilson 1916', 'Adams 1797', 'Jefferson 1802', 'Washington 1793', 'Adams 1799', 'Madison 1814', 'Washington 1790', 'Eisenhower 1956', 'Madison 1809']\n",
      "['Carter 1980', 'Carter 1981', 'Carter 1979', 'Truman 1946', 'Taft 1912', 'Taft 1911', 'Truman 1953', 'Obama 2011', 'Nixon 1972', 'Roosevelt 1906', 'Roosevelt 1901', 'Roosevelt 1907', 'McKinley 1900', 'Roosevelt 1903', 'Nixon 1974', 'Cleveland 1885', 'Eisenhower 1961', 'Jackson 1835', 'Buchanan 1857', 'Clinton 2000', 'Roosevelt 1905', 'Polk 1848', 'Buchanan 1860', 'Obama 2014', 'McKinley 1899', 'Clinton 1999', 'Bush 2006', 'Cleveland 1886', 'McKinley 1898', 'Harrison 1891', 'Fillmore 1852', 'Roosevelt 1904', 'Cleveland 1896', 'Buren 1837', 'Clinton 1998', 'Buchanan 1858', 'Taft 1910', 'Obama 2013', 'Reagan 1985', 'Buren 1839', 'Clinton 1994', 'Tyler 1843', 'Arthur 1881', 'Jackson 1834', 'Clinton 1995', 'Bush 2008', 'Cleveland 1888', 'Obama 2010', 'Carter 1978', 'Roosevelt 1908', 'Grant 1872', 'Pierce 1855', 'Buren 1838', 'Obama 2009', 'Harrison 1889', 'Coolidge 1926', 'Lincoln 1862', 'Obama 2012', 'Fillmore 1851', 'Coolidge 1925', 'Clinton 1996', 'Johnson 1867', 'Cleveland 1894', 'Buchanan 1859', 'Monroe 1824', 'Cleveland 1895', 'Tyler 1842', 'Jackson 1836', 'Clinton 1997', 'Truman 1947', 'Nixon 1971', 'Taft 1909', 'Kennedy 1962', 'Tyler 1844', 'Roosevelt 1902', 'Reagan 1987', 'Hayes 1879', 'Pierce 1854', 'Reagan 1988', 'Harrison 1890', 'Kennedy 1963', 'Ford 1975', 'Jackson 1830', 'Grant 1869', 'Ford 1977', 'Pierce 1853', 'Johnson 1868', 'Hayes 1880', 'Eisenhower 1958', 'Coolidge 1923', 'Eisenhower 1960', 'Grant 1873', 'Polk 1845', 'Adams 1825', 'Buren 1840', 'Wilson 1913', 'Johnson 1966', 'Clinton 1993', 'Harrison 1892', 'McKinley 1897', 'Eisenhower 1953', 'Coolidge 1924', 'Bush 1989', 'Pierce 1856', 'Eisenhower 1954', 'Hayes 1877', 'Arthur 1882', 'Jackson 1829', 'Harding 1921', 'Grant 1875', 'Bush 1992', 'Reagan 1984', 'Johnson 1967', 'Jackson 1831', 'Coolidge 1928', 'Adams 1826', 'Jackson 1832', 'Madison 1815', 'Johnson 1865', 'Bush 2005', 'Hoover 1929', 'Polk 1846', 'Bush 2003', 'Eisenhower 1959', 'Eisenhower 1955', 'Ford 1976', 'Jackson 1833', 'Lincoln 1861', 'Nixon 1970', 'Wilson 1915', 'Monroe 1822', 'Eisenhower 1957', 'Truman 1949', 'Wilson 1918', 'Grant 1876', 'Arthur 1884', 'Polk 1847', 'Monroe 1823', 'Reagan 1983', 'Lincoln 1864', 'Hayes 1878', 'Arthur 1883', 'Bush 2007', 'Fillmore 1850', 'Truman 1950', 'Wilson 1914', 'Wilson 1917', 'Reagan 1986', 'Harding 1922', 'Johnson 1965', 'Monroe 1817', 'Johnson 1968', 'Truman 1952', 'Roosevelt 1943', 'Cleveland 1893', 'Washington 1791', 'Adams 1827', 'Bush 1991', 'Hoover 1931', 'Roosevelt 1939', 'Taylor 1849', 'Roosevelt 1940', 'Roosevelt 1942', 'Reagan 1982', 'Kennedy 1961', 'Adams 1828', 'Monroe 1818', 'Grant 1874', 'Grant 1870', 'Nixon 1973', 'Coolidge 1927', 'Madison 1816', 'Monroe 1821', 'Johnson 1866', 'Washington 1795', 'Bush 2004', 'Washington 1796', 'Johnson 1964', 'Wilson 1919', 'Roosevelt 1934', 'Roosevelt 1936', 'Grant 1871', 'Bush 2001', 'Truman 1951', 'Washington 1793', 'Jefferson 1807', 'Cleveland 1887', 'Tyler 1841', 'Hoover 1932', 'Madison 1813', 'Washington 1792', 'Bush 1990', 'Adams 1797', 'Wilson 1920', 'Hoover 1930', 'Jefferson 1801', 'Reagan 1981', 'Roosevelt 1938', 'Wilson 1916', 'Madison 1812', 'Truman 1948', 'Madison 1814', 'Lincoln 1863', 'Washington 1794', 'Roosevelt 1945', 'Roosevelt 1941', 'Roosevelt 1944', 'Madison 1810', 'Jefferson 1805', 'Washington 1790', 'Roosevelt 1937', 'Monroe 1820', 'Bush 2002', 'Adams 1800', 'Madison 1811', 'Jefferson 1802', 'Eisenhower 1956', 'Monroe 1819', 'Jefferson 1804', 'Jefferson 1806', 'Roosevelt 1935', 'Adams 1798', 'Jefferson 1808', 'Jefferson 1803', 'Johnson 1969', 'Adams 1799', 'Madison 1809']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'an 1983'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-8217d30597c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpr2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpr2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpr1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpr1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mpr2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpr2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'an 1983'"
     ]
    }
   ],
   "source": [
    "# Exercise 2:\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Get list of presidents\n",
    "presidents = [presi.pres for presi in corpus.docs]\n",
    "years = [ye.year for ye in corpus.docs]\n",
    "\n",
    "pr1 = list(X1.keys())\n",
    "pr2 = list(X2.keys())\n",
    "\n",
    "pr1=[x[4:] for x in pr1]\n",
    "pr2=[x[4:] for x in pr2]\n",
    "\n",
    "pr1=[int(x) for x in pr1]\n",
    "pr2=[int(x) for x in pr2]\n",
    "\n",
    "pres1 = [presidents[i] for i in pr1]\n",
    "pres2 = [presidents[i] for i in pr2]\n",
    "\n",
    "year1 = [years[i] for i in pr1]\n",
    "year2 = [years[i] for i in pr2]\n",
    "\n",
    "scores1 = list(X1.values())\n",
    "scores2 = list(X2.values())\n",
    "\n",
    "\n",
    "df1 = DataFrame({\n",
    "        'president': pres1,\n",
    "        'year': year1,\n",
    "        'score1': scores1\n",
    "        })\n",
    "\n",
    "df2 = DataFrame({\n",
    "        'president': pres2,\n",
    "        'year' : year2,\n",
    "        'score1': scores2\n",
    "        })\n",
    "\n",
    "\n",
    "g1=df1.groupby(['president']).mean()\n",
    "g2=df2.groupby(['president']).mean()\n",
    "#g = df1.groupby('president').mean().sort_values(ascending=False)\n",
    "#most_rated = lens.groupby('title').size().sort_values(ascending=False)[:25]\n",
    "\n",
    "print df1\n",
    "print df2\n",
    "\n",
    "print g1\n",
    "print g2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clinton', 'Bush', 'Obama', 'Clinton', 'Obama', 'Clinton', 'Clinton', 'Clinton', 'Bush', 'Clinton', 'Bush', 'Obama', 'Clinton', 'Bush', 'Bush', 'Bush', 'Bush', 'Bush', 'Obama', 'Clinton', 'Obama', 'Obama', 'Bush', 'Bush', 'Bush', 'Reagan', 'Reagan', 'Reagan', 'Bush', 'Reagan', 'Reagan', 'Reagan']\n"
     ]
    }
   ],
   "source": [
    "pr1 = list(X1.keys())\n",
    "pr2 = list(X2.keys())\n",
    "\n",
    "pr1=[x[4:] for x in pr1]\n",
    "pr2=[x[4:] for x in pr2]\n",
    "\n",
    "pr1=[int(x) for x in pr1]\n",
    "pr2=[int(x) for x in pr2]\n",
    "\n",
    "presidents = [presi.pres for presi in corpus.docs]\n",
    "pres1 = [presidents[i] for i in pr1]\n",
    "pres2 = [presidents[i] for i in pr2]\n",
    "\n",
    "print pres1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
